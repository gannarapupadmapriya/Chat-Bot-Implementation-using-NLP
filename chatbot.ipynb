{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a190da65-1345-4e09-817e-16f8c64bf1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m file_path = os.path.abspath(\u001b[33m\"\u001b[39m\u001b[33mintents.json\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     intents = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Create the vectorizer and classifier\u001b[39;00m\n\u001b[32m     22\u001b[39m vectorizer = TfidfVectorizer()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(fp, *, \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, object_hook=\u001b[38;5;28;01mNone\u001b[39;00m, parse_float=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    275\u001b[39m         parse_int=\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant=\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook=\u001b[38;5;28;01mNone\u001b[39;00m, **kw):\n\u001b[32m    276\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python311\\Lib\\json\\__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python311\\Lib\\json\\decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    333\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m     end = _w(s, end).end()\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python311\\Lib\\json\\decoder.py:355\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    353\u001b[39m     obj, end = \u001b[38;5;28mself\u001b[39m.scan_once(s, idx)\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import csv\n",
    "import nltk\n",
    "import ssl\n",
    "import streamlit as st\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "nltk.data.path.append(os.path.abspath(\"nltk_data\"))\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load intents from the JSON file\n",
    "file_path = os.path.abspath(\"intents.json\")\n",
    "with open(file_path, \"r\") as file:\n",
    "    intents = json.load(file)\n",
    "\n",
    "# Create the vectorizer and classifier\n",
    "vectorizer = TfidfVectorizer()\n",
    "clf = LogisticRegression(random_state=0, max_iter=10000)\n",
    "\n",
    "# Preprocess the data\n",
    "tags = []\n",
    "patterns = []\n",
    "for intent in intents:\n",
    "    for pattern in intent['patterns']:\n",
    "        tags.append(intent['tag'])\n",
    "        patterns.append(pattern)\n",
    "\n",
    "# training the model\n",
    "x = vectorizer.fit_transform(patterns)\n",
    "y = tags\n",
    "clf.fit(x, y)\n",
    "\n",
    "def chatbot(input_text):\n",
    "    input_text = vectorizer.transform([input_text])\n",
    "    tag = clf.predict(input_text)[0]\n",
    "    for intent in intents:\n",
    "        if intent['tag'] == tag:\n",
    "            response = random.choice(intent['responses'])\n",
    "            return response\n",
    "        \n",
    "counter = 0\n",
    "\n",
    "def main():\n",
    "    global counter\n",
    "    st.title(\"Intents of Chatbot using NLP\")\n",
    "\n",
    "    # Create a sidebar menu with options\n",
    "    menu = [\"Home\", \"Conversation History\", \"About\"]\n",
    "    choice = st.sidebar.selectbox(\"Menu\", menu)\n",
    "\n",
    "    # Home Menu\n",
    "    if choice == \"Home\":\n",
    "        st.write(\"Welcome to the chatbot. Please type a message and press Enter to start the conversation.\")\n",
    "\n",
    "        # Check if the chat_log.csv file exists, and if not, create it with column names\n",
    "        if not os.path.exists('chat_log.csv'):\n",
    "            with open('chat_log.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "                csv_writer = csv.writer(csvfile)\n",
    "                csv_writer.writerow(['User Input', 'Chatbot Response', 'Timestamp'])\n",
    "\n",
    "        counter += 1\n",
    "        user_input = st.text_input(\"You:\", key=f\"user_input_{counter}\")\n",
    "\n",
    "        if user_input:\n",
    "\n",
    "            # Convert the user input to a string\n",
    "            user_input_str = str(user_input)\n",
    "\n",
    "            response = chatbot(user_input)\n",
    "            st.text_area(\"Chatbot:\", value=response, height=120, max_chars=None, key=f\"chatbot_response_{counter}\")\n",
    "\n",
    "            # Get the current timestamp\n",
    "            timestamp = datetime.datetime.now().strftime(f\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "            # Save the user input and chatbot response to the chat_log.csv file\n",
    "            with open('chat_log.csv', 'a', newline='', encoding='utf-8') as csvfile:\n",
    "                csv_writer = csv.writer(csvfile)\n",
    "                csv_writer.writerow([user_input_str, response, timestamp])\n",
    "\n",
    "            if response.lower() in ['goodbye', 'bye']:\n",
    "                st.write(\"Thank you for chatting with me. Have a great day!\")\n",
    "                st.stop()\n",
    "\n",
    "    # Conversation History Menu\n",
    "    elif choice == \"Conversation History\":\n",
    "        # Display the conversation history in a collapsible expander\n",
    "        st.header(\"Conversation History\")\n",
    "        # with st.beta_expander(\"Click to see Conversation History\"):\n",
    "        with open('chat_log.csv', 'r', encoding='utf-8') as csvfile:\n",
    "            csv_reader = csv.reader(csvfile)\n",
    "            next(csv_reader)  # Skip the header row\n",
    "            for row in csv_reader:\n",
    "                st.text(f\"User: {row[0]}\")\n",
    "                st.text(f\"Chatbot: {row[1]}\")\n",
    "                st.text(f\"Timestamp: {row[2]}\")\n",
    "                st.markdown(\"---\")\n",
    "\n",
    "    elif choice == \"About\":\n",
    "        st.write(\"The goal of this project is to create a chatbot that can understand and respond to user input based on intents. The chatbot is built using Natural Language Processing (NLP) library and Logistic Regression, to extract the intents and entities from user input. The chatbot is built using Streamlit, a Python library for building interactive web applications.\")\n",
    "\n",
    "        st.subheader(\"Project Overview:\")\n",
    "\n",
    "        st.write(\"\"\"\n",
    "        The project is divided into two parts:\n",
    "        1. NLP techniques and Logistic Regression algorithm is used to train the chatbot on labeled intents and entities.\n",
    "        2. For building the Chatbot interface, Streamlit web framework is used to build a web-based chatbot interface. The interface allows users to input text and receive responses from the chatbot.\n",
    "        \"\"\")\n",
    "\n",
    "        st.subheader(\"Dataset:\")\n",
    "\n",
    "        st.write(\"\"\"\n",
    "        The dataset used in this project is a collection of labelled intents and entities. The data is stored in a list.\n",
    "        - Intents: The intent of the user input (e.g. \"greeting\", \"budget\", \"about\")\n",
    "        - Entities: The entities extracted from user input (e.g. \"Hi\", \"How do I create a budget?\", \"What is your purpose?\")\n",
    "        - Text: The user input text.\n",
    "        \"\"\")\n",
    "\n",
    "        st.subheader(\"Streamlit Chatbot Interface:\")\n",
    "\n",
    "        st.write(\"The chatbot interface is built using Streamlit. The interface includes a text input box for users to input their text and a chat window to display the chatbot's responses. The interface uses the trained model to generate responses to user input.\")\n",
    "\n",
    "        st.subheader(\"Conclusion:\")\n",
    "\n",
    "        st.write(\"In this project, a chatbot is built that can understand and respond to user input based on intents. The chatbot was trained using NLP and Logistic Regression, and the interface was built using Streamlit. This project can be extended by adding more data, using more sophisticated NLP techniques, deep learning algorithms.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f8f3f0-fe9a-44e2-a782-8dea12835749",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
